{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551c2ce9-c2fa-46da-8242-6c102ad68aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee6589-0b27-4715-a934-843a48a1ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "### Fill in this information before running this section ####\n",
    "\n",
    "#Decide if you want to make a sample file\n",
    "run_hintatac_fixbeds = False\n",
    "run_hintatac_fixmpbsbeds = False\n",
    "run_hintatac_split_footprints = False\n",
    "run_hintatac_split_mpbs = False\n",
    "\n",
    "#Set number of acores\n",
    "acores = 9\n",
    "\n",
    "hintatac_dir = 'hintatac/'\n",
    "hintatac_split_dir = 'hintatac_9acoresplit/'\n",
    "hintatac_footprint_pattern = '_hintatac_all.bed'\n",
    "hintatac_footprint_fixedpattern = '_hintatac_all_fixed.bed'\n",
    "\n",
    "match_dir = 'match_all/'\n",
    "match_split_dir = 'match_all_9acoresplit/'\n",
    "match_pattern = '_hintatac_all_mpbs.bed'\n",
    "match_fixedpattern = '_hintatac_all_fixed_mpbs.bed'\n",
    "\n",
    "stage_array = ['13', '14', '15', '17', '18', '19', '19plus', '20', '21', '22', '23', '24', '25', '26', '27']\n",
    "Sstage_array = ['S' + i for i in stage_array]\n",
    "\n",
    "Mfuzz_acorebed_pattern = 'Mfuzz_' + str(acores) + 'acores_acore*_*_peaks.bed'\n",
    "\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n",
    "#HINT-ATAC generates a trailing tab for all its files, which bedtools does not like\n",
    "#Run these to fix that\n",
    "if run_hintatac_fixbeds:\n",
    "    hintatac_footprint_list = [hintatac_dir + stage + hintatac_footprint_pattern for stage in Sstage_array]\n",
    "    \n",
    "    for footprint_file in hintatac_footprint_list:\n",
    "        fixed_file = footprint_file.replace(hintatac_footprint_pattern, hintatac_footprint_fixedpattern)\n",
    "        \n",
    "        #double check to make sure you don't erase the footprint file!\n",
    "        if fixed_file == footprint_file:\n",
    "            raise ValueError(\"Fixed file and footprint file are identically named!\")\n",
    "        \n",
    "        !sed 's/\\t$//' {footprint_file} > {fixed_file}\n",
    "\n",
    "#HINT-ATAC generates a trailing tab for all its files, which bedtools does not like\n",
    "#Run these to fix that\n",
    "if run_hintatac_fixmpbsbeds:\n",
    "    match_list = [match_dir + stage + match_pattern for stage in Sstage_array]\n",
    "    \n",
    "    for match_file in match_list:\n",
    "        fixed_file = match_file.replace(match_pattern, match_fixedpattern)\n",
    "        \n",
    "        #double check to make sure you don't erase the match file!\n",
    "        if fixed_file == match_file:\n",
    "            raise ValueError(\"Fixed file and match file are identically named!\")\n",
    "        \n",
    "        !sed 's/\\t$//' {match_file} > {fixed_file}\n",
    "\n",
    "if run_hintatac_split_footprints:\n",
    "    #Generate string of all hintatac footprint bed file names\n",
    "    hintatac_footprint_list = [hintatac_dir + stage + hintatac_footprint_fixedpattern for stage in Sstage_array]\n",
    "    hintatac_footprint_string = ' '.join(hintatac_footprint_list)\n",
    "    \n",
    "    !printf \"Collecting overlaps for all footprint files listed: {hintatac_footprint_string}\\n\"\n",
    "    \n",
    "    #Iterate through number of acores\n",
    "    for acore_num in np.arange(1, acores + 1):\n",
    "        \n",
    "        #Generate names for files\n",
    "        Mfuzz_acorebed = Mfuzz_acorebed_pattern.replace('*_*', str(acore_num))\n",
    "        splitbed_filename = hintatac_split_dir + 'Sall_hintatac_all_acore' + str(acore_num) + '.bed'\n",
    "        \n",
    "        #Bedtools intersect each individual acore bed file vs. all footprint addresses\n",
    "        !bedtools intersect -a {Mfuzz_acorebed} -b {hintatac_footprint_string} -wb > {splitbed_filename}\n",
    "        \n",
    "        wb_filename = splitbed_filename.replace('.bed', '_wb.bed')\n",
    "        !printf \"getting jus the columns we want from \"{splitbed_filename}\" as \"{wb_filename}\" using pandas\\n\"\n",
    "        temp_df = pd.DataFrame(pd.read_csv(splitbed_filename, header = None, sep = '\\t'))\n",
    "        out_df = temp_df[[7, 8, 9, 10, 11, 12]]\n",
    "        out_df.to_csv(wb_filename, header = None, index = None, sep = '\\t')\n",
    "        \n",
    "        #Use sort to remove non-unique coordinates, output to a new file\n",
    "        splitbed_uniquename = wb_filename.replace('_wb.bed', '_unique.bed')\n",
    "        !printf \"removing lines from \"{wb_filename}\" with non-unique coordinates and output to \"{splitbed_uniquename}\"\\n\"\n",
    "        !sort -k1,1 -k2,2n -k3,3n -u {wb_filename} > {splitbed_uniquename}\n",
    "\n",
    "if run_hintatac_split_mpbs:\n",
    "    #Generate string of all hintatac footprint bed file names\n",
    "    match_list = [match_dir + stage + match_fixedpattern for stage in Sstage_array]\n",
    "    match_string = ' '.join(match_list)\n",
    "    \n",
    "    !printf \"Collecting overlaps for all mpbs files listed: {match_string}\\n\"\n",
    "    \n",
    "    #Iterate through number of acores\n",
    "    for acore_num in np.arange(1, acores + 1):\n",
    "        \n",
    "        #Generate names for files\n",
    "        Mfuzz_acorebed = Mfuzz_acorebed_pattern.replace('*_*', str(acore_num))\n",
    "        splitbed_filename = match_split_dir + 'Sall_hintatac_all_acore' + str(acore_num) + '_mpbs.bed'\n",
    "        \n",
    "        #Bedtools intersect each individual acore bed file vs. all footprint addresses\n",
    "        !bedtools intersect -a {Mfuzz_acorebed} -b {match_string} -wb > {splitbed_filename}\n",
    "        \n",
    "        wb_filename = splitbed_filename.replace('_mpbs.bed', '_wb_mpbs.bed')\n",
    "        !printf \"getting jus the columns we want from \"{splitbed_filename}\" as \"{wb_filename}\" using pandas\\n\"\n",
    "        temp_df = pd.DataFrame(pd.read_csv(splitbed_filename, header = None, sep = '\\t'))\n",
    "        out_df = temp_df[[7, 8, 9, 10, 11, 12]]\n",
    "        out_df.to_csv(wb_filename, header = None, index = None, sep = '\\t')\n",
    "        \n",
    "        #Use sort to remove non-unique coordinates, output to a new file\n",
    "        #Also keep any matched lines\n",
    "        splitbed_uniquename = wb_filename.replace('_wb_mpbs.bed', '_unique_mpbs.bed')\n",
    "        !printf \"removing lines from \"{wb_filename}\" with non-unique entries and output to \"{splitbed_uniquename}\"\\n\"\n",
    "        !sort -k1,1 -k2,2n -k3,3n -k4,4n -k5,5n -u {wb_filename} > {splitbed_uniquename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18914bc-a42d-49b4-8a32-0d738c86a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "### Fill in this information before running this section ####\n",
    "\n",
    "#Decide if you want to make a sample file\n",
    "run_hintatac_enrichment_mfuzz = False\n",
    "\n",
    "acores = 9\n",
    "\n",
    "hintatac_splitloc = 'hintatac_9acoresplit/'\n",
    "hintatac_splitbed = 'Sall_hintatac_all_acore*_unique.bed'\n",
    "\n",
    "match_splitloc = 'match_all_9acoresplit/'\n",
    "\n",
    "enrich_splitloc = 'enrichment_all_9acoresplit/'\n",
    "\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n",
    "if run_hintatac_enrichment_mfuzz:\n",
    "    bed_array = [hintatac_splitloc + hintatac_splitbed.replace('*', str(acore_num)) for acore_num in np.arange(1, acores + 1)]\n",
    "    bed_string = ' '.join(bed_array)\n",
    "    !rgt-motifanalysis enrichment --organism=ph5 --matching-location {match_splitloc} --motif-dbs ~/rgtdata/motifs/jaspar_core_nr --output-location {enrich_splitloc} random_regions_smaller.bed {bed_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086b1f4-1b41-451f-91d2-1065762db662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "### Fill in this information before running this section ####\n",
    "\n",
    "#Decide if you want to make a sample file\n",
    "run_hintatac_fixbeds = False\n",
    "run_hintatac_fixmpbsbeds = False\n",
    "run_hintatac_split_footprints = False\n",
    "run_hintatac_split_mpbs = False\n",
    "\n",
    "#Set number of acores\n",
    "acores = 9\n",
    "\n",
    "hintatac_dir = 'hintatac/'\n",
    "hintatac_split_dir = 'hintatac_specific_9acoresplit/'\n",
    "hintatac_footprint_pattern = '_hintatac_specific.bed'\n",
    "hintatac_footprint_fixedpattern = '_hintatac_specific_fixed.bed'\n",
    "\n",
    "match_dir = 'match_specific/'\n",
    "match_split_dir = 'match_specific_9acoresplit/'\n",
    "match_pattern = '_hintatac_specific_mpbs.bed'\n",
    "match_fixedpattern = '_hintatac_specific_fixed_mpbs.bed'\n",
    "\n",
    "stage_array = ['13', '14', '15', '17', '18', '19', '19plus', '20', '21', '22', '23', '24', '25', '26', '27']\n",
    "Sstage_array = ['S' + i for i in stage_array]\n",
    "\n",
    "Mfuzz_acorebed_pattern = 'Mfuzz_' + str(acores) + 'acores_acore*_*_peaks.bed'\n",
    "\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n",
    "#HINT-ATAC generates a trailing tab for all its files, which bedtools does not like\n",
    "#Run these to fix that\n",
    "if run_hintatac_fixbeds:\n",
    "    hintatac_footprint_list = [hintatac_dir + stage + hintatac_footprint_pattern for stage in Sstage_array]\n",
    "    \n",
    "    for footprint_file in hintatac_footprint_list:\n",
    "        fixed_file = footprint_file.replace(hintatac_footprint_pattern, hintatac_footprint_fixedpattern)\n",
    "        \n",
    "        #double check to make sure you don't erase the footprint file!\n",
    "        if fixed_file == footprint_file:\n",
    "            raise ValueError(\"Fixed file and footprint file are identically named!\")\n",
    "        \n",
    "        !sed 's/\\t$//' {footprint_file} > {fixed_file}\n",
    "\n",
    "#HINT-ATAC generates a trailing tab for all its files, which bedtools does not like\n",
    "#Run these to fix that\n",
    "if run_hintatac_fixmpbsbeds:\n",
    "    match_list = [match_dir + stage + match_pattern for stage in Sstage_array]\n",
    "    \n",
    "    for match_file in match_list:\n",
    "        fixed_file = match_file.replace(match_pattern, match_fixedpattern)\n",
    "        \n",
    "        #double check to make sure you don't erase the match file!\n",
    "        if fixed_file == match_file:\n",
    "            raise ValueError(\"Fixed file and match file are identically named!\")\n",
    "        \n",
    "        !sed 's/\\t$//' {match_file} > {fixed_file}\n",
    "\n",
    "if run_hintatac_split_footprints:\n",
    "    #Generate string of all hintatac footprint bed file names\n",
    "    hintatac_footprint_list = [hintatac_dir + stage + hintatac_footprint_fixedpattern for stage in Sstage_array]\n",
    "    hintatac_footprint_string = ' '.join(hintatac_footprint_list)\n",
    "    \n",
    "    !printf \"Collecting overlaps for all footprint files listed: {hintatac_footprint_string}\\n\"\n",
    "    \n",
    "    #Iterate through number of acores\n",
    "    for acore_num in np.arange(1, acores + 1):\n",
    "        \n",
    "        #Generate names for files\n",
    "        Mfuzz_acorebed = Mfuzz_acorebed_pattern.replace('*_*', str(acore_num))\n",
    "        splitbed_filename = hintatac_split_dir + 'Sall_hintatac_specific_acore' + str(acore_num) + '.bed'\n",
    "        \n",
    "        #Bedtools intersect each individual acore bed file vs. all footprint addresses\n",
    "        !bedtools intersect -a {Mfuzz_acorebed} -b {hintatac_footprint_string} -wb > {splitbed_filename}\n",
    "        \n",
    "        wb_filename = splitbed_filename.replace('.bed', '_wb.bed')\n",
    "        !printf \"getting jus the columns we want from \"{splitbed_filename}\" as \"{wb_filename}\" using pandas\\n\"\n",
    "        temp_df = pd.DataFrame(pd.read_csv(splitbed_filename, header = None, sep = '\\t'))\n",
    "        out_df = temp_df[[7, 8, 9, 10, 11, 12]]\n",
    "        out_df.to_csv(wb_filename, header = None, index = None, sep = '\\t')\n",
    "        \n",
    "        #Use sort to remove non-unique coordinates, output to a new file\n",
    "        splitbed_uniquename = wb_filename.replace('_wb.bed', '_unique.bed')\n",
    "        !printf \"removing lines from \"{wb_filename}\" with non-unique coordinates and output to \"{splitbed_uniquename}\"\\n\"\n",
    "        !sort -k1,1 -k2,2n -k3,3n -u {wb_filename} > {splitbed_uniquename}\n",
    "\n",
    "if run_hintatac_split_mpbs:\n",
    "    #Generate string of all hintatac footprint bed file names\n",
    "    match_list = [match_dir + stage + match_fixedpattern for stage in Sstage_array]\n",
    "    match_string = ' '.join(match_list)\n",
    "    \n",
    "    !printf \"Collecting overlaps for all mpbs files listed: {match_string}\\n\"\n",
    "    \n",
    "    #Iterate through number of acores\n",
    "    for acore_num in np.arange(1, acores + 1):\n",
    "        \n",
    "        #Generate names for files\n",
    "        Mfuzz_acorebed = Mfuzz_acorebed_pattern.replace('*_*', str(acore_num))\n",
    "        splitbed_filename = match_split_dir + 'Sall_hintatac_specific_acore' + str(acore_num) + '_mpbs.bed'\n",
    "        \n",
    "        #Bedtools intersect each individual acore bed file vs. all footprint addresses\n",
    "        !bedtools intersect -a {Mfuzz_acorebed} -b {match_string} -wb > {splitbed_filename}\n",
    "        \n",
    "        wb_filename = splitbed_filename.replace('_mpbs.bed', '_wb_mpbs.bed')\n",
    "        !printf \"getting jus the columns we want from \"{splitbed_filename}\" as \"{wb_filename}\" using pandas\\n\"\n",
    "        temp_df = pd.DataFrame(pd.read_csv(splitbed_filename, header = None, sep = '\\t'))\n",
    "        out_df = temp_df[[7, 8, 9, 10, 11, 12]]\n",
    "        out_df.to_csv(wb_filename, header = None, index = None, sep = '\\t')\n",
    "        \n",
    "        #Use sort to remove non-unique coordinates, output to a new file\n",
    "        #Also keep any matched lines\n",
    "        splitbed_uniquename = wb_filename.replace('_wb_mpbs.bed', '_unique_mpbs.bed')\n",
    "        !printf \"removing lines from \"{wb_filename}\" with non-unique entries and output to \"{splitbed_uniquename}\"\\n\"\n",
    "        !sort -k1,1 -k2,2n -k3,3n -k4,4n -k5,5n -u {wb_filename} > {splitbed_uniquename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b5ddd-8129-4670-a7a1-d39b1e09a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "### Fill in this information before running this section ####\n",
    "\n",
    "#Decide if you want to make a sample file\n",
    "run_hintatac_enrichment_mfuzz = True\n",
    "\n",
    "acores = 9\n",
    "\n",
    "hintatac_splitloc = 'hintatac_specific_9acoresplit/'\n",
    "hintatac_splitbed = 'Sall_hintatac_specific_acore*_unique.bed'\n",
    "\n",
    "match_splitloc = 'match_specific_9acoresplit/'\n",
    "\n",
    "enrich_splitloc = 'enrichment_specific_9acoresplit/'\n",
    "\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n",
    "if run_hintatac_enrichment_mfuzz:\n",
    "    bed_array = [hintatac_splitloc + hintatac_splitbed.replace('*', str(acore_num)) for acore_num in np.arange(1, acores + 1)]\n",
    "    bed_string = ' '.join(bed_array)\n",
    "    !rgt-motifanalysis enrichment --organism=ph5 --matching-location {match_splitloc} --motif-dbs ~/rgtdata/motifs/jaspar_core_nr --output-location {enrich_splitloc} random_regions_smaller.bed {bed_string}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
